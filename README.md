# Hierarchical Sparsity–Quantization–Rank LoRA

## Project Overview
Joint meta-learning framework for layer-wise sparsity, quantization, and rank optimization.

## Structure
- src/: source code modules  
- data/: datasets and preprocessing  
- notebooks/: exploratory analysis  
- output/: logs, checkpoints, and results

## Setup
```bash
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```
# Hierarchical-LoRA-Learning-Per-Layer-Compression-Policies-for-Efficient-Transformer-Scaling
